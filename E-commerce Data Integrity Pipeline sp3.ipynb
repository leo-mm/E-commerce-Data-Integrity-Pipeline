{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Instacart Grocery Basket Analysis\n",
    "## Data Cleaning and Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Project Overview\n",
    "\n",
    "This project focuses on cleaning and preparing a transactional dataset from Instacart for an in-depth analysis of customer behavior. The goal in this initial phase is purely data wrangling to ensure a reliable and clean foundation for any subsequent exploratory analysis (EDA).\n",
    "\n",
    "The process covers loading the five linked tables, inspecting the data for issues, and resolving common problems like missing values and duplicates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Dictionary\n",
    "\n",
    "We are working with five interconnected tables:\n",
    "\n",
    "- **`instacart_orders.csv`**: Contains order metadata (e.g., `order_id`, `user_id`, `order_dow`).\n",
    "- **`products.csv`**: Product catalog (`product_id`, `product_name`, `aisle_id`, `department_id`).\n",
    "- **`order_products.csv`**: Line items for each order (`order_id`, `product_id`, `add_to_cart_order`, `reordered`).\n",
    "- **`aisles.csv`**: Aisle names.\n",
    "- **`departments.csv`**: Department names."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Step 1. Initial Data Inspection\n",
    "\n",
    "First, I'll load all five CSV files and quickly check their structure to identify any obvious issues with data types, missing values, or formats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files loaded successfully from the specified path.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Setting the absolute file path based on local machine setup\n",
    "file_path_base = 'C:/Users/Note/Desktop/sprints/sprint 3/'\n",
    "\n",
    "try:\n",
    "    # Load datasets using the semicolon separator (sep=';')\n",
    "    df_instacart_orders = pd.read_csv(file_path_base + 'instacart_orders.csv', sep=';')\n",
    "    df_prod = pd.read_csv(file_path_base + 'products.csv', sep=';')\n",
    "    df_aisles = pd.read_csv(file_path_base + 'aisles.csv', sep=';')\n",
    "    df_depart = pd.read_csv(file_path_base + 'departments.csv', sep=';')\n",
    "    df_order_products = pd.read_csv(file_path_base + 'order_products.csv', sep=';')\n",
    "    print(\"All files loaded successfully from the specified path.\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: CSV files not found in '{file_path_base}'. Please check your file path.\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Checking Data Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Orders Table Info ---\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 478967 entries, 0 to 478966\n",
      "Data columns (total 6 columns):\n",
      " #   Column                  Non-Null Count   Dtype  \n",
      "---  ------                  --------------   -----  \n",
      " 0   order_id                478967 non-null  int64  \n",
      " 1   user_id                 478967 non-null  int64  \n",
      " 2   order_number            478967 non-null  int64  \n",
      " 3   order_dow               478967 non-null  int64  \n",
      " 4   order_hour_of_day       478967 non-null  int64  \n",
      " 5   days_since_prior_order  450148 non-null  float64\n",
      "dtypes: float64(1), int64(5)\n",
      "memory usage: 21.9 MB\n",
      "\n",
      "--- Products Table Info ---\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 49694 entries, 0 to 49693\n",
      "Data columns (total 4 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   product_id     49694 non-null  int64 \n",
      " 1   product_name   48436 non-null  object\n",
      " 2   aisle_id       49694 non-null  int64 \n",
      " 3   department_id  49694 non-null  int64 \n",
      "dtypes: int64(3), object(1)\n",
      "memory usage: 1.5+ MB\n",
      "\n",
      "--- Order Products Table Info ---\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4545007 entries, 0 to 4545006\n",
      "Data columns (total 4 columns):\n",
      " #   Column             Dtype  \n",
      "---  ------             -----  \n",
      " 0   order_id           int64  \n",
      " 1   product_id         int64  \n",
      " 2   add_to_cart_order  float64\n",
      " 3   reordered          int64  \n",
      "dtypes: float64(1), int64(3)\n",
      "memory usage: 138.7 MB\n",
      "\n",
      "--- Aisles Table Info ---\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 134 entries, 0 to 133\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   aisle_id  134 non-null    int64 \n",
      " 1   aisle     134 non-null    object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 2.2+ KB\n",
      "\n",
      "--- Departments Table Info ---\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 21 entries, 0 to 20\n",
      "Data columns (total 2 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   department_id  21 non-null     int64 \n",
      " 1   department     21 non-null     object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 468.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Orders Table Info ---\")\n",
    "df_instacart_orders.info()\n",
    "\n",
    "print(\"\\n--- Products Table Info ---\")\n",
    "df_prod.info()\n",
    "\n",
    "print(\"\\n--- Order Products Table Info ---\")\n",
    "df_order_products.info()\n",
    "\n",
    "print(\"\\n--- Aisles Table Info ---\")\n",
    "df_aisles.info()\n",
    "\n",
    "print(\"\\n--- Departments Table Info ---\")\n",
    "df_depart.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Initial Findings\n",
    "\n",
    "The inspection confirmed a few issues that need fixing:\n",
    "\n",
    "1.  **Missing Data:** `days_since_prior_order`, `product_name`, and `add_to_cart_order` all have missing values.\n",
    "2.  **Type Mismatch:** The missing values forced `days_since_prior_order` and `add_to_cart_order` to be `float`s, but they are clearly numerical counts and should be `int`s."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Step 2. Data Cleaning\n",
    "\n",
    "Now, I'll tackle duplicates and missing values, explaining the strategy for each fix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## A. Handling Duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Orders Table (`df_instacart_orders`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explicit duplicates found: 15\n",
      "Duplicates after removal: 0\n"
     ]
    }
   ],
   "source": [
    "print(f\"Explicit duplicates found: {df_instacart_orders.duplicated().sum()}\")\n",
    "\n",
    "# Remove explicit duplicates and reset index\n",
    "df_instacart_orders = df_instacart_orders.drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "print(f\"Duplicates after removal: {df_instacart_orders.duplicated().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Takeaway:** We found and removed 15 identical rows. This was likely a logging error during data merge/collection. It's fixed now, and the index is clean."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Order Products Table (`df_order_products`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explicit duplicates found: 0\n",
      "Duplicates after removal: 0\n"
     ]
    }
   ],
   "source": [
    "print(f\"Explicit duplicates found: {df_order_products.duplicated().sum()}\")\n",
    "\n",
    "# Remove explicit duplicates and reset index\n",
    "df_order_products = df_order_products.drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "print(f\"Duplicates after removal: {df_order_products.duplicated().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Takeaway:** A larger number of explicit duplicates (1,073) were found and removed here. This emphasizes the need for data cleaning before analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Products Table (`df_prod`): Implicit Duplicates Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of implicit duplicates (product names - case-insensitive): 1361\n"
     ]
    }
   ],
   "source": [
    "# Checking for implicit duplicates (e.g., 'Milk' vs 'milk')\n",
    "implicit_dups_count = df_prod['product_name'].str.lower().duplicated().sum()\n",
    "print(f\"Number of implicit duplicates (product names - case-insensitive): {implicit_dups_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Takeaway:** We found 1,361 implicit duplicates. Since each product has a unique `product_id`, I'll leave these for now but will remember to standardize case later if I use product names for grouping."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## B. Handling Missing Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Orders Table: `days_since_prior_order`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values before imputation: 28817\n",
      "Missing values after imputation: 0\n"
     ]
    }
   ],
   "source": [
    "print(f\"Missing values before imputation: {df_instacart_orders['days_since_prior_order'].isnull().sum()}\")\n",
    "\n",
    "# Replace NaN with 0, as this logically represents the customer's first order.\n",
    "df_instacart_orders['days_since_prior_order'] = df_instacart_orders['days_since_prior_order'].fillna(0)\n",
    "\n",
    "print(f\"Missing values after imputation: {df_instacart_orders['days_since_prior_order'].isnull().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reasoning:** Since these NaNs only appear on `order_number` 1, they represent the first order. Replacing them with **0** makes sense and is necessary to convert the column to an integer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Products Table: `product_name`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values before imputation: 1258\n",
      "Missing values after imputation: 0\n"
     ]
    }
   ],
   "source": [
    "print(f\"Missing values before imputation: {df_prod['product_name'].isnull().sum()}\")\n",
    "\n",
    "# Replace missing names with 'unknown' since we can't recover the true name.\n",
    "df_prod['product_name'] = df_prod['product_name'].fillna('unknown')\n",
    "\n",
    "print(f\"Missing values after imputation: {df_prod['product_name'].isnull().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reasoning:** Replacing the 1,258 missing names with **'unknown'** is the safest bet. This keeps the products traceable by their IDs without guessing the name."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Order Products Table: `add_to_cart_order`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values before imputation: 836\n",
      "Missing values after imputation: 0\n"
     ]
    }
   ],
   "source": [
    "print(f\"Missing values before imputation: {df_order_products['add_to_cart_order'].isnull().sum()}\")\n",
    "\n",
    "# Impute missing cart order values with 999 as a distinct placeholder.\n",
    "df_order_products['add_to_cart_order'] = df_order_products['add_to_cart_order'].fillna(999)\n",
    "\n",
    "print(f\"Missing values after imputation: {df_order_products['add_to_cart_order'].isnull().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reasoning:** The order sequence is missing for many items. Using **999** is a good placeholder because it's far outside the normal range, preventing the average cart order from being distorted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## C. Correcting Data Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "days_since_prior_order converted to int.\n",
      "add_to_cart_order converted to int.\n",
      "\n",
      "--- Verification of Data Types ---\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 478952 entries, 0 to 478951\n",
      "Data columns (total 6 columns):\n",
      " #   Column                  Non-Null Count   Dtype\n",
      "---  ------                  --------------   -----\n",
      " 0   order_id                478952 non-null  int64\n",
      " 1   user_id                 478952 non-null  int64\n",
      " 2   order_number            478952 non-null  int64\n",
      " 3   order_dow               478952 non-null  int64\n",
      " 4   order_hour_of_day       478952 non-null  int64\n",
      " 5   days_since_prior_order  478952 non-null  int32\n",
      "dtypes: int32(1), int64(5)\n",
      "memory usage: 20.1 MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4545007 entries, 0 to 4545006\n",
      "Data columns (total 4 columns):\n",
      " #   Column             Dtype\n",
      "---  ------             -----\n",
      " 0   order_id           int64\n",
      " 1   product_id         int64\n",
      " 2   add_to_cart_order  int32\n",
      " 3   reordered          int64\n",
      "dtypes: int32(1), int64(3)\n",
      "memory usage: 121.4 MB\n"
     ]
    }
   ],
   "source": [
    "# Convert float columns to integer type now that NaNs are handled\n",
    "\n",
    "df_instacart_orders['days_since_prior_order'] = df_instacart_orders['days_since_prior_order'].astype(int)\n",
    "print(\"days_since_prior_order converted to int.\")\n",
    "\n",
    "df_order_products['add_to_cart_order'] = df_order_products['add_to_cart_order'].astype(int)\n",
    "print(\"add_to_cart_order converted to int.\")\n",
    "\n",
    "# Quick check of the resulting types\n",
    "print(\"\\n--- Verification of Data Types ---\")\n",
    "df_instacart_orders.info()\n",
    "df_order_products.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Final Summary\n",
    "\n",
    "The data is now clean and structured for analysis:\n",
    "\n",
    "1.  **Duplicates:** All explicit duplicates were removed from the `orders` and `order_products` tables.\n",
    "2.  **Missing Values:** Missing values were logically handled: **0** for first orders, **'unknown'** for product names, and **999** as a distinct placeholder for unknown cart order sequences.\n",
    "3.  **Data Types:** Numerical count columns were efficiently converted to **integer** type.\n",
    "\n",
    "The datasets are ready for the next phase of the project: Exploratory Data Analysis (EDA)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
